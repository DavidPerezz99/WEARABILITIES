{"cells":[{"cell_type":"code","source":["import pandas as pd \nimport json\nimport math \nfrom pandas import json_normalize\nimport numpy as np \nfrom datetime import datetime \nfrom pyspark.sql import SparkSession\n\n#storage_account_name = \"wearabilitiesdatalake\"\n#storage_account_access_key = \"KJwuJeolHGFTaCxOtJ85OczQuGaqd5ZX7KGwaZJuv3RbETBcZDuqds4H577Ll5UOlUNIPcU1joC7EZF8QU8InA==\"\n#file_location = \"https://wearabilitiesdatalake.blob.core.windows.net/wearabilitiesfilesystem/data/dbo_User.csv\"\n#file_type = \"csv\"\n#spark.conf.set(\n#  \"fs.azure.account.key.\"+storage_account_name+\".blob.core.windows.net\",\n#  storage_account_access_key)\n#user_df = spark.read.format(file_type).option(\"inferSchema\", \"true\").load(file_location)\n\nuser_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_User.csv\",inferSchema=\"True\",header=\"True\").toPandas()\ndeliverycue_df = spark.read.csv(\"/mnt/datalakegen2/data/DeliveryCue.csv\",inferSchema=\"True\",header=\"True\").toPandas()\ndeliverycue_splittedbyelement_df = spark.read.csv(\"/mnt/datalakegen2/Cont1/Splitted_byelemtns_devcue-00001.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n#category_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Category.csv\",inferSchema=\"True\",header=\"True\").toPandas()\ncountry_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Country.csv\",inferSchema=\"True\",header=\"True\").toPandas()\ndiagnosis_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Diagnosis.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n#files_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Files.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n#gender_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Gender.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nindividualdiagnosis_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_IndividualDiagnosis.csv\",inferSchema=\"True\",header=\"True\").toPandas()\norganizationrole_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_OrganizationRole.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n#race_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Race.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n#refreshtoken_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_RefreshToken.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nrelationship_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Relationship.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nrole_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_Role.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nuser_device = spark.read.csv(\"/mnt/datalakegen2/data/dbo_UserDevice.csv\",inferSchema=\"True\",header=\"True\").toPandas()\ndeliverycue_splittedbydevid_df = spark.read.csv(\"/mnt/datalakegen2/Cont1/CaregiverDevCue_DEVIDsplitted-00001.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nindividual_diagnosis_df = spark.read.csv(\"/mnt/datalakegen2/data/dbo_IndividualDiagnosis.csv\",inferSchema=\"True\",header=\"True\").toPandas()\nscenes = spark.read.csv(\"/mnt/datalakegen2/Cont1/Scenes_devcue-00001.csv\",inferSchema=\"True\",header=\"True\").toPandas()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef8b50c6-6a83-4a7b-a2fb-697c79ff4913"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/spark/python/pyspark/sql/pandas/utils.py:91: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [Phone] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/sql/pandas/utils.py:91: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [Phone] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### CAREGIVER DATASETS GENERATION"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85ea5059-4db8-47e1-9414-9f5c5f47a1e9"}}},{"cell_type":"code","source":["caregiver_patient = user_df.groupby(['IdParent'])['IdParent'].count()\ncaregiver_patient_df = pd.DataFrame(caregiver_patient)\ncaregiver_patient_df.rename(columns = {'IdParent':'Individuals'}, inplace = True)\ncaregiver_patient_df.reset_index(inplace=True)\ncaregiver_patient_df.rename(columns = {'IdParent':'CaregiverID'}, inplace = True)\ncaregiver_id = user_df[user_df['IdRole'] == 3]['Id']\ncgv_id = [int(item) for item in caregiver_id]\norganization_id = user_df[user_df['IdRole'] == 4]['Id']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a3ec358-0443-4ddc-8381-1ae89446aed1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import ast \nfrom ast import literal_eval\ndef ___convert_to_ts(d):\n  return datetime.strptime(np.datetime_as_string(d,unit='s'), '%Y-%m-%dT%H:%M:%S').timestamp()\ndef ___convert_to_datetime(d):\n  return datetime.strptime(np.datetime_as_string(d,unit='s'), '%Y-%m-%dT%H:%M:%S')\n\ncaregiver_devcuetimerecord = pd.DataFrame(columns=['CaregiverID','DailyRecord','WeeklyRecord','MonthlyRecord','HistoricalRecord','AssignedUserCount','ElementUsage','LatestCueDate','TotalizedClassification','TotalizedType'])\ndeliverycue_table_temp = pd.DataFrame(columns = ['CaregiverID','DevCueID','DeviceID','IndividualsData','ST_total_devcue','AT_total_devcue'])\nuserdata_by_devcue = pd.DataFrame();\nDELIVERYCUE_FINAL_TAB = pd.DataFrame();\n#deliverycue_table_temp=[];\nscenes_df = scenes.assign(DeviceId=scenes.DeviceId.str.split(\"|\")).explode('DeviceId')\nscenes_df = scenes_df.reset_index();\ncaregiver_deliverycue_count = scenes_df.groupby(['PartitionKey'])['PartitionKey'].count()\ncaregiver_deliverycue_count_df = pd.DataFrame(caregiver_deliverycue_count)\ncaregiver_deliverycue_count_df.rename(columns = {'PartitionKey':'DeliveryCueCount'}, inplace = True)\ncaregiver_deliverycue_count_df.reset_index(inplace=True)\ncaregiver_deliverycue_count_df.rename(columns = {'PartitionKey':'UserID'}, inplace = True)\nscene_data = pd.DataFrame(columns=['CaregiverID','SceneID','SceneType','AnswerType'])\nfor index in scenes_df.index:\n        key = scenes_df['RowKey'][index];\n        caregiver_id = scenes_df['PartitionKey'][index];\n        title = scenes_df['Title'][index];\n        date = scenes_df['CreationDate'][index];\n        device = scenes_df['DeviceId'][index] \n        temp_temp = scenes_df['Scenes'][index];#scenes_df[scenes_df['RowKey'] == key]['DeviceId'].item()\n        user_list = pd.DataFrame(columns=['UserID'])\n        user_data = pd.DataFrame(columns=['CodeUser','UserName','UserCountry','UserProfilePic'])\n        #print(temp_temp);\n                \n        if len(user_device[user_device['DeviceCode'] == device]['IdUser']) == 0:\n            user_item = 0;\n            user_firstname = '';\n            user_lastname = '';\n            user_complete_name = user_firstname + user_lastname;\n            user_country = '';\n            user_profile_pic = '';\n            user_diagnosis_code = '';\n            diagnosis_list = '';\n            \n        else:\n            user_item = user_device[user_device['DeviceCode'] == device]['IdUser'].item()\n            user_firstname = user_df[user_df['Id'] == user_item]['Name'].item();\n            user_lastname = user_df[user_df['Id'] == user_item]['LastName'].item();\n            user_complete_name = user_firstname +' '+ user_lastname;\n            user_country_code = user_df[user_df['Id'] == user_item]['IdCountry'].item();\n            user_country = country_df[country_df['Id'] == user_country_code]['Name'].item();\n            user_profile_pic = user_df[user_df['Id'] == user_item]['ProfilePicture'].item();\n            user_diagnosis_code_list = individual_diagnosis_df[individual_diagnosis_df['IdUser']==user_item]['IdDiagnosis'].tolist()\n            user_diagnosis = pd.DataFrame(columns=['Diagnosis'])\n            for item in user_diagnosis_code_list: \n                user_diagnosis = user_diagnosis.append({\n                    'Diagnosis':diagnosis_df[diagnosis_df['Id']==item]['Name'].item()\n                },ignore_index=True) \n                \n            diagnosis_list = user_diagnosis.Diagnosis.tolist()\n        user_data = user_data.append(\n                    {'CodeUser':int(user_item),\n                    'UserName':user_complete_name,\n                    'UserCountry':user_country,\n                    'UserProfilePic':user_profile_pic,\n                    'Diagnosis':str(diagnosis_list)},\n                    ignore_index=True\n                )\n        user_data = user_data.to_dict('records')\n        #print(user_data.columns)}\n        scene_data_buff = pd.DataFrame(columns=['SceneID','SceneType','AnswerType'])\n        temp_temp = json.loads(temp_temp)\n        for x in temp_temp:            \n            temp_df = pd.DataFrame.from_dict(x, orient='index')\n            temp_df = temp_df.transpose();\n            #print(temp_df['Id'].item())\n            scene_data_buff = scene_data_buff.append(\n                {'SceneID':temp_df['Id'].item(),\n                'CueImage':temp_df['Image'].item(),\n                'SceneType':temp_df['SceneType'].item(),\n                'AnswerType':temp_df['AnswerType'].item(),\n                'CaregiverID':caregiver_id},\n                ignore_index=True\n            )\n        sc_data_buff = (scene_data_buff.groupby(['SceneType','AnswerType']).size().sort_values(ascending=False).reset_index(name='Count').drop_duplicates(subset='AnswerType'))\n        sc_data_buff['SceneType'] = sc_data_buff['SceneType'].replace([1],'Static')\n        sc_data_buff['SceneType'] = sc_data_buff['SceneType'].replace([2],'Dynamic')\n        sc_data_buff['SceneType'] = sc_data_buff['SceneType'].replace([3],'Spoken')\n        sc_data_buff['AnswerType'] = sc_data_buff['AnswerType'].replace([1],'Unanswered')\n        sc_data_buff['AnswerType'] = sc_data_buff['AnswerType'].replace([2],'Yes/No')\n        sc_data_buff['AnswerType'] = sc_data_buff['AnswerType'].replace([3],'Multiple')\n        sc_data_buff.rename(columns={'SceneType':'ClassificationType'},inplace=True)\n        sc_data_buff.rename(columns={'AnswerType':'Type'},inplace=True)\n        scenetype_perdevcue = sc_data_buff[['ClassificationType','Count']]\n        scenetype_perdevcue = pd.DataFrame(scenetype_perdevcue.groupby(['ClassificationType'])['ClassificationType'].count())\n        scenetype_perdevcue .rename(columns={'ClassificationType':'Count'},inplace=True)\n        scenetype_perdevcue .reset_index(inplace=True)\n        answertype_perdevcue = sc_data_buff[['Type','Count']]\n        answertype_perdevcue = pd.DataFrame(answertype_perdevcue.groupby(['Type'])['Type'].count())\n        answertype_perdevcue.rename(columns={'Type':'Count'},inplace=True)\n        answertype_perdevcue.reset_index(inplace=True)\n        scenetype_perdevcue = scenetype_perdevcue.to_dict(orient = 'records')\n        answertype_perdevcue= answertype_perdevcue.to_dict(orient = 'records')\n        #print(scenetype_perdevcue)\n#        sc_data_buff.rename(columns={'AnswerType':'type'},inplace=True)\n#        scenetype_perdevcue  =  pd.DataFrame(scene_data_buff.groupby(['SceneType'])['SceneType'].count())\n#        scenetype_perdevcue .rename(columns={'SceneType':'Count'},inplace=True)\n#        scenetype_perdevcue .reset_index(inplace=True)\n#        #scenetype_perdevcue = scene_data_buff['SceneType'].item()\n#        answertype_perdevcue  =  pd.DataFrame(scene_data_buff.groupby(['AnswerType'])['AnswerType'].count())\n#        answertype_perdevcue .rename(columns={'AnswerType':'Count'},inplace=True)\n#        answertype_perdevcue .reset_index(inplace=True)\n#        #answertype_perdevcue = scene_data_buff['AnswerType'].item()\n        image = scene_data_buff['CueImage'][0]\n#        scene_data = scene_data.append(scene_data_buff,ignore_index=True)\n#        #.sort_values(ascending=False) \n#        #.reset_index(name='count') ).to_dict('dict')\n#        #answertype_perdevcue =  (scene_data_buff.groupby(['AnswerType']).size()\n#        #.sort_values(ascending=False) \n#        #.reset_index(name='count') ).to_dict('dict')\n        deliverycue_table_temp = deliverycue_table_temp.append(\n            {'CaregiverID':scenes_df['PartitionKey'][index],\n            'DevCueID':key,\n            'TitleDelivery':title,\n            'DeviceID':device,\n            'DateDelivery':str(date),\n            'ImageDelivery':image,\n            'IndividualsData':user_data,\n            'ST_total_devcue':str(scenetype_perdevcue),\n            'AT_total_devcue':str(answertype_perdevcue)},\n            ignore_index=True)\n#        deliverycue_table_temp['ST_total_devcue'] = deliverycue_table_temp['ST_total_devcue'].replace([1],'Static')\n#        deliverycue_table_temp['ST_total_devcue'] = deliverycue_table_temp['ST_total_devcue'].replace([2],'Dynamic')\n#        deliverycue_table_temp['ST_total_devcue'] = deliverycue_table_temp['ST_total_devcue'].replace([3],'Spoken')\n#        deliverycue_table_temp['AT_total_devcue'] = deliverycue_table_temp['AT_total_devcue'].replace([1],'Unanswered')\n#        deliverycue_table_temp['AT_total_devcue'] = deliverycue_table_temp['AT_total_devcue'].replace([2],'Yes/No')\n#        deliverycue_table_temp['AT_total_devcue'] = deliverycue_table_temp['AT_total_devcue'].replace([3],'Multiple')\nfor index in deliverycue_table_temp.index:\n    buff = deliverycue_table_temp['IndividualsData'][index]\n    userdata_df_temp = pd.json_normalize(buff[0])\n    userdata_by_devcue = userdata_by_devcue.append(userdata_df_temp,ignore_index=True)\nDELIVERYCUE_FINAL_TAB = pd.concat([deliverycue_table_temp, userdata_by_devcue], axis=1)\nDELIVERYCUE_FINAL_TAB = DELIVERYCUE_FINAL_TAB.drop(columns=['IndividualsData'])\nDELIVERYCUE_FINAL_TAB['index_column'] = DELIVERYCUE_FINAL_TAB.index;\nDELIVERYCUE_FINAL_TAB.fillna('[]', inplace=True)\nsparkDF=spark.createDataFrame(DELIVERYCUE_FINAL_TAB) \nsparkDF.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"/mnt/datalakegen2/stats/caregiver/CAREGIVER_DEVCUE\")\ndata_location = \"/mnt/datalakegen2/stats/caregiver/CAREGIVER_DEVCUE\"\nfiles = dbutils.fs.ls(data_location)\ncsv_file = [x.path for x in files if x.path.endswith(\".csv\")][0]\ndbutils.fs.mv(csv_file, data_location.rstrip('/') + \".csv\")\ndbutils.fs.rm(data_location, recurse = True)\n#\n#        \n#        \n#scene_data_by_cgv =  pd.DataFrame(scene_data.groupby(['CaregiverID']))\n#scene_data_by_cgv.rename(columns={0:'CaregiverID',1:'Data'},inplace=True)\n#cgv_totals = pd.DataFrame()\n#    classf_data.rename(columns={'ClassificationType':'Count'},inplace=True)\n#    classf_data.reset_index(inplace=True)\n#    typef_data = typef_data.groupby(['Type'])['Type'].count()\n#    typef_data.rename(columns={'Type':'Count'},inplace=True)\n#    typef_data.reset_index(inplace=True)\n    \n    \n        \n#    scenetype_by_cgv =  pd.DataFrame(data.groupby(['SceneType'])['SceneType'].count())\n#    scenetype_by_cgv.rename(columns={'SceneType':'Count'},inplace=True)\n#    scenetype_by_cgv.reset_index(inplace=True)\n#    scenetype_by_cgv['SceneType'] = scenetype_by_cgv['SceneType'].replace([1],'Static')\n#    scenetype_by_cgv['SceneType'] = scenetype_by_cgv['SceneType'].replace([2],'Dynamic')\n#    scenetype_by_cgv['SceneType'] = scenetype_by_cgv['SceneType'].replace([3],'Spoken')\n#    scenetype_by_cgv.rename(columns={'SceneType':'ClassificationType'},inplace=True)\n#    #scenetype_by_cgv = scenetype_by_cgv.to_json(orient = 'records')\n#    answertype_by_cgv = pd.DataFrame(data.groupby(['AnswerType'])['AnswerType'].count())\n#    answertype_by_cgv.rename(columns={'AnswerType':'Count'},inplace=True)\n#    answertype_by_cgv.reset_index(inplace=True)\n#    answertype_by_cgv['AnswerType'] = answertype_by_cgv['AnswerType'].replace([1],'Unanswered')\n#    answertype_by_cgv['AnswerType'] = answertype_by_cgv['AnswerType'].replace([2],'Yes/No')\n#    answertype_by_cgv['AnswerType'] = answertype_by_cgv['AnswerType'].replace([3],'Multiple')\n#    answertype_by_cgv.rename(columns={'AnswerType':'Type'},inplace=True)\n#    type_data = answertype_by_cgv.to_json(orient='records')\n#    classification_data = scenetype_by_cgv.to_json(orient='records')\n#    #print('********')\n#    #print(scenetype_by_cgv)\n#    #print(answertype_by_cgv)\n#    #print('********')\n#    #answertype_by_cgv = answertype_by_cgv.to_json(orient = 'records')\n#    #cgv_totals = cgv_totals.append({\n#    #    'CaregiverID':cgv,\n#    #    'Scenetype_report':scenetype_by_cgv[scenetype_by_cgv['']],\n#    #    'Answertype_report':answertype_by_cgv\n#    #},ignore_index=True)\n#    if 'Static' in scenetype_by_cgv['ClassificationType'].unique(): \n#        static_cue_total = scenetype_by_cgv[scenetype_by_cgv['ClassificationType']=='Static']['Count'].item() \n#    else: \n#        static_cue_total = 0   \n#    if 'Spoken' in scenetype_by_cgv['ClassificationType'].unique(): \n#        spoken_cue_total = scenetype_by_cgv[scenetype_by_cgv['ClassificationType']=='Spoken']['Count'].item() \n#    else: \n#        spoken_cue_total = 0 \n#    if 'Dynamic' in scenetype_by_cgv['ClassificationType'].unique():\n#        dynamic_cue_total = scenetype_by_cgv[scenetype_by_cgv['ClassificationType']=='Dynamic']['Count'].item()\n#    else: \n#        dynamic_cue_total = 0\n#    if 'Unanswered' in answertype_by_cgv['Type'].unique():\n#        unanswered_cue_total = answertype_by_cgv[answertype_by_cgv['Type']=='Unanswered']['Count'].item()\n#    else:\n#        unanswered_cue_total = 0\n#    if 'Yes/No' in answertype_by_cgv['Type'].unique():\n#        yes_no_cue_total = answertype_by_cgv[answertype_by_cgv['Type']=='Yes/No']['Count'].item()\n#    else:\n#        yes_no_cue_total = 0\n#    if 'Multiple' in answertype_by_cgv['Type'].unique():\n#        multiple_cue_total = answertype_by_cgv[answertype_by_cgv['Type']=='Multiple']['Count'].item()\n#    else:\n#        multiple_cue_total = 0               \n#\n#    \n#    cgv_totals = cgv_totals.append({\n#        'CaregiverID':cgv,\n#        'TotalizedClassification':classification_data,\n#        'TotalizedType':type_data\n#    },ignore_index=True)\n#cgv_totals['CaregiverID'] =  [int(item) for item in cgv_totals['CaregiverID']]\nfor cgvid in cgv_id :\n    scenetype_data = deliverycue_table_temp[deliverycue_table_temp['CaregiverID']==cgvid]['ST_total_devcue'].tolist()\n    answertype_data = deliverycue_table_temp[deliverycue_table_temp['CaregiverID']==cgvid]['AT_total_devcue'].tolist()\n    classf_data = pd.DataFrame()\n    typef_data = pd.DataFrame()\n    for j in range(len(scenetype_data)):\n        tempclass_df = ast.literal_eval(scenetype_data[j])\n        tempclass_df = pd.DataFrame(tempclass_df)\n        temptype_df = ast.literal_eval(answertype_data[j])\n        temptype_df = pd.DataFrame(temptype_df)\n        classf_data = classf_data.append(tempclass_df,ignore_index=True)\n        typef_data = typef_data.append(temptype_df,ignore_index=True)\n    if 'ClassificationType' in classf_data.columns: \n        classf_data = pd.DataFrame(classf_data.groupby(['ClassificationType']).sum()).reset_index()\n    if 'Type' in typef_data.columns: \n        typef_data = pd.DataFrame(typef_data.groupby(['Type']).sum()).reset_index()\n    user_dates = deliverycue_df[deliverycue_df['PartitionKey'] == cgvid]['Timestamp']  \n    devcuetype = pd.DataFrame(deliverycue_splittedbyelement_df[deliverycue_splittedbyelement_df['PartitionKey'] == cgvid]['ElementType'])\n    user_info_buff = pd.DataFrame(columns=['Name','UserID','Diagnosis','ProfilePic','Age'])\n    rowkey_index = scenes_df[scenes_df['PartitionKey'] == cgvid]['RowKey'].tolist();\n\n        \n    if len(devcuetype) == 0: \n        devcuetype = pd.DataFrame(columns=['ElementType','Count']);\n    else: \n        devcuetype = pd.DataFrame(devcuetype.groupby(['ElementType'])['ElementType'].count())\n        devcuetype.rename(columns = {'ElementType':'Count'}, inplace = True)\n        devcuetype.reset_index(inplace=True)\n    file_stamp = str(devcuetype.to_json(orient = 'records'))\n        \n    user_dates = user_dates.sort_values()\n    if len(caregiver_patient_df[caregiver_patient_df['CaregiverID'] == cgvid]['Individuals']) == 0: \n        auc = 0; \n    else: \n        auc = caregiver_patient_df[caregiver_patient_df['CaregiverID'] == cgvid]['Individuals'].item()\n    if len(user_dates) == 0:\n        daily_record = 0; \n        weekly_record = 0; \n        monthly_record = 0;\n        user_devcue_count = 0;\n        last_devcue_sent = '';\n    else:\n        daily_record = (user_dates.iloc[-1] - user_dates.iloc[0]).days\n        daily_record = int(daily_record)\n        weekly_record = daily_record/7\n        monthly_record = daily_record/30\n        user_devcue_count = caregiver_deliverycue_count_df[caregiver_deliverycue_count_df['UserID'] == cgvid ]['DeliveryCueCount'].item()\n        user_devcue_count = int(user_devcue_count)\n        last_devcue_sent = user_dates.iloc[-1];\n    if daily_record == 0 :\n        daily_record = 1;\n    if weekly_record == 0 : \n        weekly_record = 1; \n    if monthly_record == 0 : \n        monthly_record = 1;     \n    daily_rate = user_devcue_count/ daily_record\n    weekly_rate = user_devcue_count/weekly_record\n    monthly_rate = user_devcue_count / monthly_record \n    classification_data = classf_data.to_json(orient='records')\n    type_data = typef_data.to_json(orient='records')\n    caregiver_devcuetimerecord = caregiver_devcuetimerecord.append(\n        {'CaregiverID' : cgvid, \n         'DailyRecord' : daily_rate, \n         'WeeklyRecord' :weekly_rate,\n         'MonthlyRecord':monthly_rate,\n         'HistoricalRecord': user_devcue_count,\n         'AssignedUserCount': auc,\n         'ElementUsage': file_stamp,\n         'LatestCueDate':str(last_devcue_sent),\n         'TotalizedClassification':str(classification_data),\n         'TotalizedType':str(type_data)},\n        ignore_index = True)\n    caregiver_devcuetimerecord['index_column'] = caregiver_devcuetimerecord.index;\n    \nsparkDF=spark.createDataFrame(caregiver_devcuetimerecord) \nsparkDF.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"/mnt/datalakegen2/stats/caregiver/CAREGIVER\")\ndata_location = \"/mnt/datalakegen2/stats/caregiver/CAREGIVER\"\nfiles = dbutils.fs.ls(data_location)\ncsv_file = [x.path for x in files if x.path.endswith(\".csv\")][0]\ndbutils.fs.mv(csv_file, data_location.rstrip('/') + \".csv\")\ndbutils.fs.rm(data_location, recurse = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7525b49c-3450-4484-8599-e70f38aa1ac4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[3]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: True"]}}],"execution_count":0},{"cell_type":"markdown","source":["### ORGANIZATION DATASETS GENERATION"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3becb270-8484-4c82-a0bb-efa4c87ade9e"}}},{"cell_type":"code","source":["organization_report_table = pd.DataFrame(columns = ['Organization_Id','Caregiver_Data','Caregiver_Count','ElementUsage','TotalizedClassification','TotalizedType','DailyRecord','WeeklyRecord','MonthlyRecord','HistoricalRecord'])\nuser_parent = user_df.groupby(['IdParent'])['IdParent'].count()\nuser_parent  = pd.DataFrame(user_parent)\nuser_parent.rename(columns={'IdParent':'ParentCount'},inplace=True)\nuser_parent.reset_index(inplace=True)\nuser_parent.rename(columns={'IdParent':'UserId'},inplace=True)\nuser_parent\n\nfor Id in organization_id: \n    if len(user_parent[user_parent['UserId'] == Id]['ParentCount']) == 0: \n        org_parent = 0; \n    else: \n        org_parent = user_parent[user_parent['UserId'] == Id]['ParentCount'].item()\n    org_user_list = [];\n    org_user_list = user_df[user_df['IdParent']==Id]['Id'].tolist()\n    caregiver_data = pd.DataFrame(columns=  ['CaregiverID','DailyRecord','WeeklyRecord','MonthlyRecord','HistoricalRecord','AssignedUserCount','ElementUsage'])\n    org_element_usage = pd.DataFrame(columns=['ElementType','Count'])\n    org_class = pd.DataFrame()\n    org_type = pd.DataFrame()\n    org_totals = pd.DataFrame(columns=['DailyRecord','WeeklyRecord','MonthlyRecord','HistoricalRecord'])\n    unassigned_users = 0 ; \n    for x in org_user_list: \n        pull_data = pd.DataFrame(caregiver_devcuetimerecord[caregiver_devcuetimerecord['CaregiverID']== x])\n        if pull_data['AssignedUserCount'].item() == 0: \n            unassigned_users = unassigned_users + 1\n        \n        assigned_users = len(org_user_list) - unassigned_users\n        daily_record_buff = pull_data['DailyRecord'].item()\n        weekly_record_buff = pull_data['WeeklyRecord'].item()\n        monthly_record_buff = pull_data['MonthlyRecord'].item()\n        historical_record_buff = pull_data['HistoricalRecord'].item()\n        org_totals = org_totals.append({'DailyRecord':daily_record_buff,\n                                       'WeeklyRecord':weekly_record_buff,\n                                       'MonthlyRecord':monthly_record_buff,\n                                       'HistoricalRecord':historical_record_buff},ignore_index=True)\n        caregiver_elementusage_item = pull_data['ElementUsage'].item()\n        caregiver_class_item = pull_data['TotalizedClassification'].item()\n        caregiver_type_item = pull_data['TotalizedType'].item()\n        if caregiver_elementusage_item == '0': \n            print('caregiver has no history data');\n        else:\n            caregiver_elementusage_item = pd.read_json(caregiver_elementusage_item, orient='records')\n            caregiver_class_item = pd.read_json(caregiver_class_item , orient='records')\n            caregiver_type_item = pd.read_json(caregiver_type_item , orient='records')\n            org_element_usage = org_element_usage.append(caregiver_elementusage_item,ignore_index=True)\n            org_class = org_class.append(caregiver_class_item,ignore_index=True)\n            org_type = org_type.append(caregiver_type_item,ignore_index=True)\n            print(org_class.columns)\n        caregiver_data = caregiver_data.append(pull_data)\n    org_element_usage = pd.DataFrame(org_element_usage.groupby(['ElementType']).sum()).reset_index().to_json(orient='records')\n    if 'ClassificationType' in org_class.columns:\n        org_class = pd.DataFrame(org_class.groupby(['ClassificationType']).sum()).reset_index().to_json(orient='records')\n        org_type = pd.DataFrame(org_type.groupby(['Type']).sum()).reset_index().to_json(orient='records')\n    else:\n        org_class = []\n        org_type = []\n    \n    file_stamp = str(caregiver_data.to_json(orient = 'records'))\n    organization_report_table = organization_report_table.append(\n    {'Organization_Id' : Id, \n     'Caregiver_Data' : file_stamp, \n     'Caregiver_Count' : org_parent,\n     'ElementUsage':str(org_element_usage),\n     'TotalizedClassification':str(org_class),\n     'TotalizedType':str(org_type),\n     'DailyRecord':org_totals['DailyRecord'].mean(),\n     'WeeklyRecord':org_totals['WeeklyRecord'].mean(),\n     'MonthlyRecord':org_totals['MonthlyRecord'].mean(),\n     'HistoricalRecord':org_totals['HistoricalRecord'].sum(),\n     'Assigned': assigned_users,\n     'NotAssigned':unassigned_users\n    },\n    ignore_index = True)\n    organization_report_table['index_column'] = organization_report_table.index;\n    \nsparkDF=spark.createDataFrame(organization_report_table) \nsparkDF.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"/mnt/datalakegen2/stats/organization/ORGANIZATION\")\ndata_location = \"/mnt/datalakegen2/stats/organization/ORGANIZATION\"\nfiles = dbutils.fs.ls(data_location)\ncsv_file = [x.path for x in files if x.path.endswith(\".csv\")][0]\ndbutils.fs.mv(csv_file, data_location.rstrip('/') + \".csv\")\ndbutils.fs.rm(data_location, recurse = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32e10ce0-7daa-426a-a167-8d041886991c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Index(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nOut[4]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Index(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex(['ClassificationType', 'Count'], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nIndex([], dtype='object')\nOut[4]: True"]}}],"execution_count":0},{"cell_type":"markdown","source":["### INDIVIDUAL DATASETS GENERATION"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d065d3c3-de9e-410b-b73e-ebe2c5623c8b"}}},{"cell_type":"code","source":["individual_id = user_df[user_df['IdRole'] == 2]['Id']\nindividual_table = pd.DataFrame(columns=['IndividualID','DailyRecord','WeeklyRecord','MonthlyRecord','HistoricalRecord','ElementUsage','LatestDevCueDate'])\nindividual_devcue_table = pd.DataFrame(columns=['UserId','DeliveryCueList','Classification_total','Type_total']);\n\nfor Id in individual_id:\n    devices = user_device[user_device['IdUser']==Id]['DeviceCode'].tolist()\n    total_class = pd.DataFrame();\n    total_type = pd.DataFrame();\n    user_deliverycue_history = pd.DataFrame()\n    if not devices:\n        user_deliverycue_history = pd.DataFrame(columns={'CaregiverID':[''],\n            'DevCueID':[''],\n            'TitleDelivery':[''],\n            'DeviceID':[''],\n            'DateDelivery':[''],\n            'ImageDelivery':[''],\n            'ST_total_devcue':[''],\n            'AT_total_devcue':['']\n                                                        });\n        user_deliverycue_history = user_deliverycue_history.to_dict('records')\n        #classf_data={'ClassificationType':['Static','Spoken','Dynamic'],'Count':[0,0,0]}\n        #tp_data  = {'Type':['Unanswered','Yes/No','Multiple'],'Count':[0,0,0]}\n        #total_class = pd.DataFrame(columns={'Static':[0],\n        #                                          'Dynamic':[0],\n        #                                          'Spoken':[0]});\n        #total_type = pd.DataFrame(columns={\n        #    'Unanswered':[0],\n        #    'Yes_no':[0],\n        #    'Multiple':[0]\n        #})\n        #type_data = pd.DataFrame(tp_data)\n        #classification_data = pd.DataFrame(classf_data)\n        #classification_data = classification_data.to_json(orient='records')\n        #type_data = type_data.to_json(orient='records')        \n    for device in devices: \n        user_delivery_list = DELIVERYCUE_FINAL_TAB[DELIVERYCUE_FINAL_TAB['DeviceID']==device]\n        if user_delivery_list.empty: \n            user_deliverycue_history = pd.DataFrame(columns={'CaregiverID':[''],\n            'DevCueID':[''],\n            'TitleDelivery':[''],\n            'DeviceID':[''],\n            'DateDelivery':[''],\n            'ImageDelivery':[''],\n            'ST_total_devcue':[''],\n            'AT_total_devcue':['']})\n            user_deliverycue_history = user_deliverycue_history.to_dict('records')\n            #classf_data={'ClassificationType':['Static','Spoken','Dynamic'],'Count':[0,0,0]}\n            #tp_data  = {'Type':['Unanswered','Yes/No','Multiple'],'Count':[0,0,0]}\n            #total_class = pd.DataFrame(columns={'Static':[0],\n            #                                         'Dynamic':[0],\n            #                                          'Spoken':[0]});\n            #total_type = pd.DataFrame(columns={\n            #    'Unanswered':[0],\n            #    'Yes_no':[0],\n            #    'Multiple':[0]\n            #})\n            #type_data = pd.DataFrame(tp_data)\n            #classification_data = pd.DataFrame(classf_data)\n            #classification_data = classification_data.to_json(orient='records')\n            #type_data = type_data.to_json(orient='records')\n        else:\n            user_deliverycue_history = user_deliverycue_history.append(user_delivery_list)      \n            user_deliverycue_history = user_deliverycue_history.to_dict('records')\n            scenetotal_data = user_delivery_list['ST_total_devcue'].tolist();\n            answertypetotal_data = user_delivery_list['AT_total_devcue'].tolist();\n            scenetype_perdev = pd.DataFrame()\n            type_perdev = pd.DataFrame()\n            for n in range(len(scenetotal_data)):\n                tempclass_df = ast.literal_eval(scenetotal_data[n])\n                tempclass_df = pd.DataFrame(tempclass_df)\n            for m in range(len(answertypetotal_data)): \n                temptype_df = ast.literal_eval(answertypetotal_data[m])\n                temptype_df = pd.DataFrame(temptype_df)\n                classf_data = classf_data.append(tempclass_df,ignore_index=True)\n                typef_data = typef_data.append(temptype_df,ignore_index=True)\n            if 'ClassificationType' in classf_data.columns: \n                classf_data = pd.DataFrame(classf_data.groupby(['ClassificationType']).sum()).reset_index()\n            if 'Type' in typef_data.columns: \n                typef_data = pd.DataFrame(typef_data.groupby(['Type']).sum()).reset_index()\n        total_class = total_class.append(classf_data,ignore_index=True)\n        total_type = total_type.append(typef_data,ignore_index=True)\n    if 'ClassificationType' in total_class.columns: \n        total_class = pd.DataFrame(total_class.groupby(['ClassificationType']).sum()).reset_index()\n    if 'Type' in total_type.columns: \n        total_type = pd.DataFrame(total_type.groupby(['Type']).sum()).reset_index()\n                #scenetype_perdev = scenetype_perdev.append({'ClassificationType':scenetotal_data[n]},ignore_index=True)\n                #type_perdev = type_perdev.append({'Type':answertypetotal_data[n]},ignore_index=True)\n            #scenetype_perdev =  pd.DataFrame(scenetype_perdev.groupby(['SceneType'])['SceneType'].count())\n            #scenetype_perdev.rename(columns={'SceneType':'Count'},inplace=True)\n            #scenetype_perdev.reset_index(inplace=True)\n            #type_perdev =  pd.DataFrame(type_perdev.groupby(['AnswerType'])['AnswerType'].count())\n            #type_perdev.rename(columns={'AnswerType':'Count'},inplace=True)\n            #type_perdev.reset_index(inplace=True)\n#             print('********')\n#             print(scenetype_perdev['SceneType'])\n#             print(type_perdev['AnswerType'])\n#             print('*********')\n#             if 'Dynamic' in scenetype_perdev['SceneType'].values: \n#                 dynamic_cue_total = scenetype_perdev[scenetype_perdev['SceneType']=='Dynamic']['Count'].item();\n#             else: \n#                 dynamic_cue_total = 0; \n#             if 'Spoken' in scenetype_perdev['SceneType'].values: \n#                 spoken_cue_total = scenetype_perdev[scenetype_perdev['SceneType']=='Spoken']['Count'].item();\n#             else: \n#                 spoken_cue_total = 0; \n#             if 'Static' in scenetype_perdev['SceneType'].values:\n#                 static_cue_total = scenetype_perdev[scenetype_perdev['SceneType']=='Static']['Count'].item();\n#             else:\n#                 static_cue_total = 0; \n#             if 'Unanswered' in type_perdev['AnswerType'].values: \n#                 unanswered_cue_total = type_perdev[type_perdev['AnswerType']=='Unanswered']['Count'].item();\n#             else: \n#                 unanswered_cue_total = 0; \n#             if 'Yes/No' in type_perdev['AnswerType'].values: \n#                 yes_no_cue_total = type_perdev[type_perdev['AnswerType']=='Yes/No']['Count'].item(); \n#             else: \n#                 yes_no_cue_total = 0; \n#             if 'Multiple' in type_perdev['AnswerType'].values: \n#                 multiple_cue_total = type_perdev[type_perdev['AnswerType']=='Multiple']['Count'].item(); \n#             else: \n#                 multiple_cue_total = 0;\n#             classf_data={'ClassificationType':['Static','Spoken','Dynamic'],'Count':[static_cue_total,spoken_cue_total,dynamic_cue_total]}\n#             tp_data  = {'Type':['Unanswered','Yes/No','Multiple'],'Count':[unanswered_cue_total,yes_no_cue_total,multiple_cue_total]}\n#             total_class = pd.DataFrame(classf_data)\n#             total_type = pd.DataFrame(tp_data)\n    classification_data = total_class.to_json(orient='records')\n    type_data = total_type.to_json(orient='records')\n        #type_data = type_data.to_json(orient='records')\n    individual_devcue_table = individual_devcue_table.append({\n        'UserId':Id,\n        'DeliveryCueList':str(user_deliverycue_history),\n        'Classification_total':str(classification_data),\n        'Type_total':str(type_data)\n         },ignore_index=True)\nINDIVIDUAL_DEVCUE_TAB = pd.DataFrame()\nfor index in individual_devcue_table.index:\n    data = ast.literal_eval(individual_devcue_table['DeliveryCueList'][index])\n    Id = individual_devcue_table['UserId'][index]\n    if not data:\n        print()\n    else:\n        master_copy = individual_devcue_table[individual_devcue_table['UserId']==Id]\n        userdata_by_devcue = pd.DataFrame();\n        copy_table = pd.DataFrame()\n        for i in range(len(data)):\n            copy_table = copy_table.append(master_copy,ignore_index=True)\n            row = pd.json_normalize(data[i])\n            userdata_by_devcue = userdata_by_devcue.append(row,ignore_index=True)\n            #temp_df = pd.DataFrame(data)\n        deliverytable_by_user = pd. concat([copy_table, userdata_by_devcue], axis=1)\n        INDIVIDUAL_DEVCUE_TAB = INDIVIDUAL_DEVCUE_TAB.append(deliverytable_by_user,ignore_index=True)\nINDIVIDUAL_DEVCUE_TAB['index_column'] = INDIVIDUAL_DEVCUE_TAB.index;\nsparkDF=spark.createDataFrame(INDIVIDUAL_DEVCUE_TAB) \nsparkDF.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"/mnt/datalakegen2/stats/individual/INDIVIDUAL_DEVCUE\")\ndata_location = \"/mnt/datalakegen2/stats/individual/INDIVIDUAL_DEVCUE\"\nfiles = dbutils.fs.ls(data_location)\ncsv_file = [x.path for x in files if x.path.endswith(\".csv\")][0]\ndbutils.fs.mv(csv_file, data_location.rstrip('/') + \".csv\")\ndbutils.fs.rm(data_location, recurse = True)\n  \n\nfor Id in individual_id:\n    individual_devcue_id_list = INDIVIDUAL_DEVCUE_TAB[INDIVIDUAL_DEVCUE_TAB['CodeUser']==Id]['DevCueID'].tolist()\n    ind_devcue_count = len(individual_devcue_id_list)\n    user_dates = INDIVIDUAL_DEVCUE_TAB[INDIVIDUAL_DEVCUE_TAB['CodeUser'] == Id]['DateDelivery']  \n    devcuetype = pd.DataFrame(columns=['ElementType','Count']);\n    for Ix in individual_devcue_id_list:\n        devcuetype_element =deliverycue_splittedbyelement_df[deliverycue_splittedbyelement_df['RowKey'] == Ix]['ElementType'].tolist()\n        for item in devcuetype_element:\n            devcuetype = devcuetype.append({'ElementType':item},ignore_index=True)\n        \n        #print(devcuetype_element)\n    devcuetype = pd.DataFrame(devcuetype.groupby(['ElementType'])['ElementType'].count())\n    devcuetype.rename(columns = {'ElementType':'Count'}, inplace = True)\n    devcuetype.reset_index(inplace=True)         \n    file_stamp = str(devcuetype.to_json(orient = 'records'))\n    user_dates = user_dates.sort_values()\n    if len(caregiver_patient_df[caregiver_patient_df['CaregiverID'] == Id]['Individuals']) == 0: \n        auc = 0; \n    else: \n        auc = caregiver_patient_df[caregiver_patient_df['CaregiverID'] == Id]['Individuals'].item()\n    if len(user_dates) == 0:\n        daily_record = 0; \n        weekly_record = 0; \n        monthly_record = 0;\n        user_devcue_count = 0;\n        last_devcue_sent = '';\n    else:\n        last =datetime.strptime(user_dates.iloc[-1], '%Y-%m-%d %H:%M:%S.%f')\n        first = datetime.strptime(user_dates.iloc[0], '%Y-%m-%d %H:%M:%S.%f')\n        daily_record = ( last-first ).days\n        daily_record = int(daily_record)\n        weekly_record = daily_record/7\n        monthly_record = daily_record/30\n        user_devcue_count = len(individual_devcue_id_list )\n        user_devcue_count = int(user_devcue_count)\n        last_devcue_sent = user_dates.iloc[-1];\n    if daily_record == 0 :\n        daily_record = 1;\n    if weekly_record == 0 : \n        weekly_record = 1; \n    if monthly_record == 0 : \n        monthly_record = 1;     \n    daily_rate = user_devcue_count/ daily_record\n    weekly_rate = user_devcue_count/weekly_record\n    monthly_rate = user_devcue_count / monthly_record\n    classification_total = individual_devcue_table[individual_devcue_table['UserId']==Id]['Classification_total'].item()\n    type_total = individual_devcue_table[individual_devcue_table['UserId']==Id]['Type_total'].item()\n    \n    individual_table = individual_table.append(\n        {'IndividualID' : Id, \n         'DailyRecord' : daily_rate, \n         'WeeklyRecord' :weekly_rate,\n         'MonthlyRecord':monthly_rate,\n        'HistoricalRecord': user_devcue_count,\n        'ElementUsage': file_stamp,\n        'LatestDevCueDate':last_devcue_sent,\n        'TotalizedClassification':classification_total,\n        'TotalizedType':type_total},\n        ignore_index = True)\n    individual_table['index_column'] = individual_table.index;\nsparkDF=spark.createDataFrame(individual_table) \nsparkDF.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"/mnt/datalakegen2/stats/individual/INDIVIDUAL\")\ndata_location = \"/mnt/datalakegen2/stats/individual/INDIVIDUAL\"\nfiles = dbutils.fs.ls(data_location)\ncsv_file = [x.path for x in files if x.path.endswith(\".csv\")][0]\ndbutils.fs.mv(csv_file, data_location.rstrip('/') + \".csv\")\ndbutils.fs.rm(data_location, recurse = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5cebd2f1-7f59-41f9-89ab-8a486b48eb5a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut[29]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut[29]: True"]}}],"execution_count":0},{"cell_type":"code","source":["individual_table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b5e417e-653f-4a64-a515-7306396534e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IndividualID</th>\n      <th>DailyRecord</th>\n      <th>WeeklyRecord</th>\n      <th>MonthlyRecord</th>\n      <th>HistoricalRecord</th>\n      <th>ElementUsage</th>\n      <th>LatestDevCueDate</th>\n      <th>TotalizedClassification</th>\n      <th>TotalizedType</th>\n      <th>index_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>278</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>280</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>281</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>285</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>447</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>448</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>449</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>451</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9</td>\n      <td>[{\"ElementType\":\"Audio\",\"Count\":2},{\"ElementTy...</td>\n      <td>2022-07-13 17:21:29.979145</td>\n      <td>[{\"ClassificationType\":\"Static\",\"Count\":110}]</td>\n      <td>[{\"Type\":\"Multiple\",\"Count\":34},{\"Type\":\"Unans...</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n<p>91 rows × 10 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IndividualID</th>\n      <th>DailyRecord</th>\n      <th>WeeklyRecord</th>\n      <th>MonthlyRecord</th>\n      <th>HistoricalRecord</th>\n      <th>ElementUsage</th>\n      <th>LatestDevCueDate</th>\n      <th>TotalizedClassification</th>\n      <th>TotalizedType</th>\n      <th>index_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>278</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>280</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>281</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>285</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>447</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>448</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>449</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td></td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>451</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9</td>\n      <td>[{\"ElementType\":\"Audio\",\"Count\":2},{\"ElementTy...</td>\n      <td>2022-07-13 17:21:29.979145</td>\n      <td>[{\"ClassificationType\":\"Static\",\"Count\":110}]</td>\n      <td>[{\"Type\":\"Multiple\",\"Count\":34},{\"Type\":\"Unans...</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n<p>91 rows × 10 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### ADMIN DATASETS GENERATION"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc3f9365-8745-4276-9bee-a64b94c3efa0"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DATASET_GENERATION","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4257683298547307}},"nbformat":4,"nbformat_minor":0}
